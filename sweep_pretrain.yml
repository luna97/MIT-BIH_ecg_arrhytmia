program: sweep_pretrain.py
method: random
name: pretrain-xLSTM
metric:
  goal: minimize
  name: test_loss
parameters:
  pretrain:
    value: True
  lr:
    min: 0.00001
    max: 0.001
  wd:
    min: 0.0001
    max: 0.1
  batch_size:
    value: 128
  epochs:
    value: 20
  optimizer:
    value: "adamw"
  patch_size:
    values: [128, 256]
  embedding_size:
    values: [784, 512, 256]
  activation_fn:
    value: 'relu'
  xlstm_depth:
    value: 7
  dropout:
    value: 0.3
  normalize:
    value: True
  wandb_log:
    value: True
  random_shift:
    value: True
  data_folder_mit:
    value: '/media/Volume/data/MIT-BHI/data/'
  pretrain_with_code15:
    value: True
  num_workers:
    value: 4
  nk_clean:
    value: True
  use_scheduler:
    value: True
  data_folder_code15:
    value: '/media/Volume/data/CODE15/unlabeled_records_360_nkclean'
  multi_token_prediction: 
    value: True
  loss_type:
    values: ['grad', 'mse']
  num_epochs_warmup:
    value: 2
  num_epochs_warm_restart:
    value: 5
  patch_embedding:
    value: 'linear'
  deterministic:
    value: True
  is_sweep:
    value: True